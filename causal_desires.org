#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/style.css">
#+OPTIONS: num:nil toc:nil html-postamble:nil

#+TITLE: Causal Desires

"Why?"

The question we -- children, scientists, scorned lovers, irate customers -- *all* love. We can't help ourselves! We need a story, ideally one that's easy to understand and fits with other stories we know. It's a little slice of reality where things happen as we expect, where we feel we understand, where we could plan or possibly effect outcomes.

Some of us like to take this to extremes, engaging in formal study to learn some really good why-stories. Why-stories which are carefully framed, with well-probed boundaries and beautiful caveats. Universal why-stories or incredibly specific ones, couched in numbers or careful analysis.

It is then no surprise that the art of why-storying itself is also formalized, so let us also be formal and call it causation. Aristotle loved it and students today, well, at least tolerate it and dutifully learn that causation is not correlation. 

To study causality when there's a lot happening -- lots of possible variables, observations, effects -- it's easy to lose intuition. Pearl's causal calculus provides a scalable framework for drawing conclusions regarding causality [fn:1]. This approach is rigorous, but starts from the modeller specifying a graph which shows which variables can affect other variables. This makes explicit an uncomfortable point: causality is a model property. The causal calculus tells you some non-obvious fact about the assumptions and observations you've made, but is subject to possible mismatch between assumptions and reality -- a point nicely detailed in Norton's [[https://www.pitt.edu/~jdnorton/papers/003004.pdf]['Causation as Folk Science']]. 

The principle concern of causal calculus is formal decision making [fn:2]; questions like 'does smoking cause cancer' or 'does this intervention cause this health outcome'. This has two major distinctions from causal reasoning in our daily lives: it is a labor-intensive decision making process, and the result is a single statement. Decisions of daily life are messy and hasty, at varying levels of explication. Critically, they often occur or re-occur over longer time periods, embedded in and interacting with our communities and environment. 

With repeated decisions, the situation is more complex: our actions affect our surroundings, which in turn affects us again. Whether to go to the gym, whether to pick up flowers for your partner, these are decisions which shape our world and turn back, shaping our expectations, perceptions, and our future decisions.

Consider a simple rational agent, choosing actions to achieve a desired outcome. This agent is using some model which translates an action into outcome, a counterfactual if-this-then-that which is one theory of mind [fn:4]. This forward model (action -> outcome) impacts the agent's actions, but may be incomplete. Specifically, it may be a simplified causal story which is missing how that action echos back. 

For example, I feel warmth and love towards my partner and, on the way home, buy them flowers. One causal story here is feeling love -> buy flowers. However, such acts of love also heighten and draw attention to my feelings of love, i.e. buying flowers also cause feelings of love. Such acts also (probably) affect my partner and encourage reciprocal acts, which similarly amplify these feelings. It's not that mood unilaterally causes actions but, as Nussbaum puts it, 'we inhabit our expressions' [fn:3].  

In that example, the incomplete story of feeling love -> buy flowers would likely work just as well as a more complex story. But, in general, an incomplete causal story leaves room for plausible stories which invert the causality - where the effect is presented as a cause. The self-fullfilling prophecy is a sort of causality inversion, positive visualization another.

Like any story, a causal story is a framing which centers certain facts and insights, and hides others. By being aware of our human need for a causal story, we can greet these stories of cause and effect with an appropriate amount of skepticism.  It may be that flipping the causality - considering the effect as a cause - provides useful insights.  

Some examples:

[fn:1] Pearl and Mackenzie, 'The Book of Why: The New Science of Cause and Effect', a number of shorter introductions [[https://www.inference.vc/untitled/][available]].
[fn:2] Although the causal graph can be extended to consider a time series, this is decidedly not the focus of the text.
[fn:3] Nussbaum, "Love and the Individual: Romantic Rightness and Platonic Aspiration" 
[fn:4] This theory of decision making is not the only one; see, e.g. [[https://arxiv.org/abs/1901.01291]['On the Utility of Model Learning in HRI']] by Choudhury, et al.

** Moore's law
Moore's law, the empirical rule of thumb that, in commercial semiconductor fabrication, the transistor count per chip doubles every two years. This observation, credited to Gordon Moore of Intel in 1965, was, at the time of its coinage, a model for predicting what computing power would be reasonable to expect in the future. This is a story which helps software developers, consumers, and corporations plan their investments.

However, as many have noted, Moore's law does more than predict: it is also a benchmark, setting the industry tempo, driving R&D direction and funding. By seeing it in this flipped causality (that Moore's law induces development), a company could decide to try to invest more and push past it, or that keeping pace is not strategic.
 
** Eternal salvation
A prototypical religious view is that righteous actions cause eternal salvation. The Puritans, especially Calvinists, typically espouse a form of predestination: that one does not choose salvation, but rather that 'the privilege of choice is God's alone'. Good behavior *results* from being elected for salvation, but does not *cause* it.

How does such a viewpoint affect a community who believes themselves to be elected for salvation? Would they seek to save those who are not similarly endowed by destiny? How could an individual own up to a bad action in their past and keep moving forward with hope for salvation? Inverting the causality here seems to result in stronger bifurcations of behavior.

** Technology development
Let us say, for the sake of argument, that a technology is a means to reaching certain ends. Let's call this ability to do things an 'affordance'. What is a causal story of technology creation?  One is that someone invests resources in hopes of achieving an affordance. For example, we created a material that has a higher strength-to-weight ratio, or an algorithm which allows faster optimization of a class of problems. In this story, the technology is caused by a desire for an affordance.

However, some development is driven by a need, where existing or new technologies are designed for a specific problem. For example, I need to hold a door open and find a book nearby, or I need to scale neural networks and create TPUs. In this story, technology is caused by a specific need.

These complementary stories are sometimes called basic (or curiosity-driven or push)  vs. application-driven (or pull) development. 

All development is a mixture of the two, but typically one dominates the framing for a funding agency, investor, or other decision maker. For example, the DARPA research model is a 'right-to-left' method (presumably technologies move from left to right as they move down a pipeline): look at what novel use-cases could fit their agency scope/objectives, then go 'shopping' in more basic research to find and foster supporting technologies, herding them towards this future use-case.

This bi-directional causality, where technical capability and need co-create each other, is one thing that makes R&D difficult. This difficulty is exacerbated by the tendency of a person to stick to a single framing. For us engineers, the overwhelming tendency is to see technology development as the goal: to create something which meets certain specifications. But for a technology to become widespread, it also needs to meet a need.

One way to compare R&D organizations is the mechanism used to mediate need and technical capability. In companies, explicit roles like product managers own customer needs and communicate them to the engineers. For the academic research community, use-cases are often left more vague, as general visions (e.g. make robots easier to program). These visions are shaped by the community, built within the current paradigm.  A major skill for academic researchers is to convincingly connect their technical work to the vision of their audience.
