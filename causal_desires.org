#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/style.css">
#+OPTIONS: num:nil toc:nil html-postamble:nil

#+TITLE: Causal Desires

"Why?"

The question we -- children, scientists, scorned lovers, irate customers -- *all* love. We can't help ourselves! We need a story, ideally one that's easy to understand and fits with other stories we know. It's a little slice of reality where things happen as we expect, where we feel we understand, where we could plan or possibly effect outcomes.

Some of us take this to extremes, engaging in formal study to learn some really good why-stories. Why-stories which are carefully framed, with well-probed boundaries and beautiful caveats. Universal why-stories or incredibly specific ones, couched in numbers or careful analysis.

It is then no surprise that the art of why-storying itself is also formalized, so let us also be formal and call it causation. Aristotle loved it and students today, well, at least tolerate it and dutifully learn that causation is not correlation. 

If studying causality when there's a lot happening -- lots of possible variables, observations, effects -- it's easy to lose intuition. In such cases, Pearl's causal calculus provides a scalable framework for drawing conclusions regarding causality [fn:1]. This approach is rigorous, starting from the modeller specifying a graph which shows which variables can affect other variables. This makes explicit an uncomfortable point: causality is a model property. The causal calculus tells you some non-obvious fact about the assumptions and observations you've made, but is subject to possible mismatch between assumptions and reality -- a point nicely detailed in Norton's [[https://www.pitt.edu/~jdnorton/papers/003004.pdf]['Causation as Folk Science']]. 

The principle concern of causal calculus is formal decision making [fn:2]; questions like 'does smoking cause cancer' or 'does this intervention cause this health outcome'. This has two major distinctions from causal reasoning in our daily lives: it is a labor-intensive decision making process, and the result is a single statement. Decisions of daily life are messy and hasty, at varying levels of explication. Also, they often occur and re-occur over longer time periods, embedded in and interacting with the people, objects, and organizations that surround us. 

With repeated decisions, our actions affect our surroundings, which in turn affects us again. Whether to go to the gym, whether to pick up flowers for your partner, these are decisions which shape our world and turn back, shaping our expectations, perceptions, and our future decisions.

Consider a simple rational agent, choosing one action from many to achieve a desired outcome. This agent is using some model which translates action into outcome, a counterfactual if-this-then-that which is one theory of mind [fn:4]. This forward model (action -> outcome) impacts the agent's actions, but may be incomplete. Specifically, it may be a simplified causal story which is missing how that action echos back. 

For example, I feel warmth and love towards my partner and, on the walk home, buy them flowers. One causal story here is feeling love -> buy flowers. However, such acts of love also heighten and draw attention to my feelings of love, i.e. buying flowers also cause feelings of love. Such acts also (probably) affect my partner and encourage reciprocal acts, which similarly amplify these feelings. It's not that disposition unilaterally causes actions but, as Nussbaum puts it, 'we inhabit our expressions' [fn:3].  

In that example, the incomplete story of feeling love -> buy flowers would likely result in the same decision as someone carefully writing a complete causal graph and calculating. But, in general, an incomplete causal story leaves room for plausible stories which invert the causality - where the effect is presented as a cause. The self-fullfilling prophecy is a sort of causality inversion, positive visualization another. Your favorite TED talk might feature one, as it gives a little a-ha moment composed of pieces of the story you already know.

Like any story, a causal story is a framing which centers certain facts and insights, and hides others. But it seems humans have a unique need for causal stories, a desire for sensemaking. By being aware of our tendency for causal storytelling, we can greet them with an appropriate amount of skepticism, check them for fitness-to-purpose.

Looking at some causal stories and their flips can also give a useful way to categorize complementary ways of thinking. Some examples:

[fn:1] Pearl and Mackenzie, 'The Book of Why: The New Science of Cause and Effect', a number of shorter introductions [[https://www.inference.vc/untitled/][available]].
[fn:2] Although the causal graph can be extended to consider a time series, this is decidedly not the focus of the text.
[fn:3] Nussbaum, "Love and the Individual: Romantic Rightness and Platonic Aspiration" 
[fn:4] This theory of decision making is not the only one; see, e.g. [[https://arxiv.org/abs/1901.01291]['On the Utility of Model Learning in HRI']] by Choudhury, et al.

** Moore's law
Moore's law is the empirical rule of thumb that the transistor count per chip doubles every two years. This observation, credited to Gordon Moore of Intel in 1965, was a model for time-> computing power. This is a story which unquestionably helps software developers, consumers, and corporations plan their investments and decisions.

However, as many have noted, Moore's law does more than predict: it is also a benchmark, setting the industry tempo, driving R&D direction and funding. By seeing it in this flipped causality (Moore's law -> computing power), a company could decide to try to invest more and push past it, or that keeping pace is not strategic.
 
** Eternal salvation
A prototypical religious view is that righteous actions cause eternal salvation. The Puritans, especially Calvinists, typically espouse a form of predestination: that one does not choose salvation, but rather that 'the privilege of choice is God's alone'. Good behavior *results* from being elected for salvation, but does not *cause* it.

How does such a viewpoint affect a community who believes themselves to be elected for salvation? Would they seek to save those who are not endowed by destiny? How could one find redemption if they believe a misdeed has revealed them un-chosen? This causality seems to result in stronger bifurcations of behavior.

** Technology development
Let us say, for the sake of argument, that a technology is a means to reaching certain ends. Let's call this ability to do things an 'affordance'. What is a causal story of the creation of technology?  One is that someone invests resources in hopes of achieving an affordance. For example, we created a material that has a higher strength-to-weight ratio, or an algorithm which allows faster optimization of a class of problems. In this story, the technology is caused by a desire for an affordance.

However, some development is driven by a need, where existing or new technologies are designed for a specific problem. For example, I need to hold a door open and find a book nearby, or I need to scale neural networks and create TPUs. In this story, technology is caused by a specific need.

These complementary stories are sometimes called basic (or curiosity-driven or push)  vs. application-driven (or pull) development. 

All development is a mixture of the two, but typically one dominates the framing for a funding agency, investor, or other decision maker. For example, the DARPA research model is a 'right-to-left' method (presumably technologies move from left to right as they move down a pipeline): look at what novel use-cases could fit their agency scope/objectives, then go 'shopping' in more basic research to find and foster supporting technologies, herding them towards this future use-case.

This bi-directional causality, where affordance and need co-create each other, is one thing that makes R&D difficult. This difficulty is exacerbated by the tendency of a person to stick to a single framing. For us engineers, the overwhelming tendency is to see technology development as the goal: to create something which meets certain specifications. But for a technology to become widespread, it also needs to meet a need.

One way to compare R&D organizations is the mechanism used to mediate need and affordance. In companies, explicit roles like product managers are responsible for customer needs and represent them to engineers. For the academic research community, 'need' is left underspecified as general visions (e.g. make robots easier to program). These visions are shaped by the community, built within the current paradigm and conception of what is promising.  A major skill for academic researchers is to understand the vision of their audience and convincingly connect their technical work.  
